<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>An Introduction to Expectations via SciMLExpectations.jl · SciMLExpectations.jl</title><meta name="title" content="An Introduction to Expectations via SciMLExpectations.jl · SciMLExpectations.jl"/><meta property="og:title" content="An Introduction to Expectations via SciMLExpectations.jl · SciMLExpectations.jl"/><meta property="twitter:title" content="An Introduction to Expectations via SciMLExpectations.jl · SciMLExpectations.jl"/><meta name="description" content="Documentation for SciMLExpectations.jl."/><meta property="og:description" content="Documentation for SciMLExpectations.jl."/><meta property="twitter:description" content="Documentation for SciMLExpectations.jl."/><meta property="og:url" content="https://docs.sciml.ai/SciMLExpectations/stable/tutorials/introduction/"/><meta property="twitter:url" content="https://docs.sciml.ai/SciMLExpectations/stable/tutorials/introduction/"/><link rel="canonical" href="https://docs.sciml.ai/SciMLExpectations/stable/tutorials/introduction/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="SciMLExpectations.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">SciMLExpectations.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li class="is-active"><a class="tocitem" href>An Introduction to Expectations via SciMLExpectations.jl</a><ul class="internal"><li><a class="tocitem" href="#System-Model"><span>System Model</span></a></li><li><a class="tocitem" href="#Vector-Valued-Functions"><span>Vector-Valued Functions</span></a></li><li><a class="tocitem" href="#Higher-Order-Moments"><span>Higher-Order Moments</span></a></li><li><a class="tocitem" href="#Batch-Mode"><span>Batch-Mode</span></a></li></ul></li><li><a class="tocitem" href="../optimization_under_uncertainty/">Optimization Under Uncertainty</a></li><li><a class="tocitem" href="../gpu_bayesian/">GPU-Accelerated Data-Driven Bayesian Uncertainty Quantification with Koopman Operators</a></li><li><a class="tocitem" href="../process_noise/">Expectation of Process Noise</a></li></ul></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../../manual/problem/">ExpectationProblem</a></li><li><a class="tocitem" href="../../manual/solve/">Solving Expectation Problems</a></li><li><a class="tocitem" href="../../manual/algorithms/">Expectation Algorithms</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>An Introduction to Expectations via SciMLExpectations.jl</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>An Introduction to Expectations via SciMLExpectations.jl</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/SciMLExpectations.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/SciMLExpectations.jl/blob/master/docs/src/tutorials/introduction.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="An-Introduction-to-Expectations-via-SciMLExpectations.jl"><a class="docs-heading-anchor" href="#An-Introduction-to-Expectations-via-SciMLExpectations.jl">An Introduction to Expectations via SciMLExpectations.jl</a><a id="An-Introduction-to-Expectations-via-SciMLExpectations.jl-1"></a><a class="docs-heading-anchor-permalink" href="#An-Introduction-to-Expectations-via-SciMLExpectations.jl" title="Permalink"></a></h1><h2 id="System-Model"><a class="docs-heading-anchor" href="#System-Model">System Model</a><a id="System-Model-1"></a><a class="docs-heading-anchor-permalink" href="#System-Model" title="Permalink"></a></h2><p>First, let&#39;s consider the following linear model.</p><p class="math-container">\[u&#39; = p u\]</p><pre><code class="language-julia hljs">f(u, p, t) = p .* u</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">f (generic function with 1 method)</code></pre><p>We then wish to solve this model on the timespan <code>t=0.0</code> to <code>t=10.0</code>, with an initial condition <code>u0=10.0</code> and parameter <code>p=-0.3</code>. We can then set up the differential equations, solve, and plot as follows</p><pre><code class="language-julia hljs">using OrdinaryDiffEq, Plots
u0 = [10.0]
p = [-0.3]
tspan = (0.0, 10.0)
prob = ODEProblem(f, u0, tspan, p)
sol = solve(prob, Tsit5())
plot(sol)</code></pre><img src="39241c1c.svg" alt="Example block output"/><p>However, what if we wish to consider a random initial condition? Assume <code>u0</code> is distributed uniformly from <code>-10.0</code> to <code>10.0</code>, i.e.,</p><pre><code class="language-julia hljs">using Distributions
u0_dist = [Uniform(-10.0, 10.0)]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Distributions.Uniform{Float64}}:
 Distributions.Uniform{Float64}(a=-10.0, b=10.0)</code></pre><p>We can then run a Monte Carlo simulation of 100,000 trajectories by solving an <code>EnsembleProblem</code>.</p><pre><code class="language-julia hljs">prob_func(prob, i, repeat) = remake(prob, u0 = rand.(u0_dist))
ensemble_prob = EnsembleProblem(prob, prob_func = prob_func)

ensemblesol = solve(ensemble_prob, Tsit5(), EnsembleThreads(), trajectories = 100000)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">EnsembleSolution Solution of length 100000 with uType:
ODESolution{Float64, 2, Vector{Vector{Float64}}, Nothing, Nothing, Vector{Float64}, Vector{Vector{Vector{Float64}}}, ODEProblem{Vector{Float64}, Tuple{Float64, Float64}, false, Vector{Float64}, ODEFunction{false, SciMLBase.AutoSpecialize, typeof(Main.f), LinearAlgebra.UniformScaling{Bool}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED), Nothing, Nothing}, Base.Pairs{Symbol, Union{}, Tuple{}, @NamedTuple{}}, SciMLBase.StandardODEProblem}, OrdinaryDiffEq.Tsit5{typeof(OrdinaryDiffEq.trivial_limiter!), typeof(OrdinaryDiffEq.trivial_limiter!), Static.False}, OrdinaryDiffEq.InterpolationData{ODEFunction{false, SciMLBase.AutoSpecialize, typeof(Main.f), LinearAlgebra.UniformScaling{Bool}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED), Nothing, Nothing}, Vector{Vector{Float64}}, Vector{Float64}, Vector{Vector{Vector{Float64}}}, OrdinaryDiffEq.Tsit5ConstantCache}, DiffEqBase.Stats, Nothing}</code></pre><p>Plotting a summary of the trajectories produces</p><pre><code class="language-julia hljs">summ = EnsembleSummary(ensemblesol)
plot(summ)</code></pre><img src="3a81cbe4.svg" alt="Example block output"/><p>Given the ensemble solution, we can then compute the expectation of a function <span>$g\left(\text{sol},p\right)$</span> of the system state <code>u</code> at any time in the timespan, e.g., the state itself at <code>t=4.0</code> as</p><pre><code class="language-julia hljs">g(sol, p) = sol(4.0)
mean([g(sol, prob.p) for sol in ensemblesol])</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Float64}:
 0.008069673289187616</code></pre><p>Alternatively, SciMLExpectations.jl offers a convenient interface for this type of calculation, using <code>ExpectationProblem</code>.</p><pre><code class="language-julia hljs">using SciMLExpectations
gd = GenericDistribution(u0_dist...)
h(x, u, p) = x, p
sm = SystemMap(prob, Tsit5())
exprob = ExpectationProblem(sm, g, h, gd; nout = 1)
sol = solve(exprob, MonteCarlo(100000))
sol.u</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Float64}:
 0.007951213855970942</code></pre><p><code>ExpectationProblem</code> takes a <code>SystemMap</code>, which contains the <code>ODEProblem</code> that we are working with, and how to solve it. The function of interest <span>$g$</span>, which maps the solution of the <code>ODEProblem</code> to the quantities you want to take the expectation of, in this case the state after 4 seconds. A <code>GenericDistribution</code> containing all the aspects of the dynamical system you are uncertain about, in this example this is the initial condition. The function <span>$h$</span>, which maps a realization of the uncertainty space to the initial conditions and parameters of the <code>ODEProblem</code>. Here, only the initial conditions are uncertain, while the parameters are deterministic. See further down for an example with both uncertain initial conditions and parameters.</p><p>The <code>ExpectationProblem</code> can then be solved using an <code>AbstractExpectationAlgorithm</code>. Here we use <code>MonteCarlo()</code> to use the Monte Carlo algorithm. Recall, that <code>u0_dist = [Uniform(-10.0,10.0)]</code>, while <code>p = [-0.3]</code>. From this specification, the expectation is solved as</p><p class="math-container">\[\mathbb{E}\left[g\left(S\left(h\left(x,u_0,p\right)\right)\right)\vert x\sim \text{gd}\right]\]</p><p>where <span>$Pf$</span> is the “push-forward” density of the initial joint pdf <span>$f$</span> on initial conditions and parameters.</p><p>Alternatively, we could solve the same problem using the <code>Koopman()</code> algorithm.</p><pre><code class="language-julia hljs">sol = solve(exprob, Koopman())
sol.u</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Float64}:
 0.0</code></pre><p>Being that this system is linear, we can analytically compute the solution as a deterministic ODE with its initial condition set to the expectation of the initial condition, i.e.,</p><p class="math-container">\[e^{pt}\mathbb{E}\left[u_0\right]\]</p><pre><code class="language-julia hljs">exp(p[1] * 4.0) * mean(u0_dist[1])</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.0</code></pre><p>We see that for this case, the <code>Koopman()</code> algorithm produces a more accurate solution than <code>MonteCarlo()</code>. Not only is it more accurate, it is also much faster</p><pre><code class="language-julia hljs">@time solve(exprob, MonteCarlo(100000))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">SciMLExpectations.ExpectationSolution{Vector{Float64}, Nothing, Nothing}([-0.00829089374088893], nothing, nothing)</code></pre><pre><code class="language-julia hljs">@time solve(exprob, Koopman())</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">SciMLExpectations.ExpectationSolution{Vector{Float64}, Float64, SciMLBase.IntegralSolution{Float64, 1, Vector{Float64}, Float64, IntegralProblem{false, RecursiveArrayTools.ArrayPartition{Float64, Tuple{Vector{Float64}, Vector{Float64}}}, SciMLExpectations.var&quot;#23#24&quot;{GenericDistribution{SciMLExpectations.var&quot;#pdf_func#10&quot;{Tuple{Distributions.Uniform{Float64}}}, SciMLExpectations.var&quot;#rand_func#12&quot;{Tuple{Distributions.Uniform{Float64}}}, StaticArraysCore.SVector{1, Float64}, StaticArraysCore.SVector{1, Float64}}, typeof(Main.h), typeof(Main.g), SystemMap{ODEProblem{Vector{Float64}, Tuple{Float64, Float64}, false, Vector{Float64}, ODEFunction{false, SciMLBase.AutoSpecialize, typeof(Main.f), LinearAlgebra.UniformScaling{Bool}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED), Nothing, Nothing}, Base.Pairs{Symbol, Union{}, Tuple{}, @NamedTuple{}}, SciMLBase.StandardODEProblem}, OrdinaryDiffEq.Tsit5{typeof(OrdinaryDiffEq.trivial_limiter!), typeof(OrdinaryDiffEq.trivial_limiter!), Static.False}, EnsembleThreads, Base.Pairs{Symbol, Union{}, Tuple{}, @NamedTuple{}}}}, StaticArraysCore.SVector{1, Float64}, Base.Pairs{Symbol, Union{}, Tuple{}, @NamedTuple{}}}, HCubatureJL{typeof(LinearAlgebra.norm)}, Nothing, Nothing}}([0.0], 0.0, [0.0])</code></pre><p>Changing the distribution, we arrive at</p><pre><code class="language-julia hljs">u0_dist = [Uniform(0.0, 10.0)]
gd = GenericDistribution(u0_dist...)
exprob = ExpectationProblem(sm, g, h, gd; nout = length(u0))
sol = solve(exprob, MonteCarlo(100000))
sol.u</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Float64}:
 1.511621737955049</code></pre><p>and</p><pre><code class="language-julia hljs">u0_dist = [Uniform(0.0, 10.0)]
gd = GenericDistribution(u0_dist...)
exprob = ExpectationProblem(sm, g, h, gd; nout = length(u0))
sol = solve(exprob, Koopman())
sol.u</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Float64}:
 1.5059722132990783</code></pre><p>where the analytical solution is</p><pre><code class="language-julia hljs">exp(p[1] * 4.0) * mean(u0_dist[1])</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1.5059710595610107</code></pre><p>Note that the <code>Koopman()</code> algorithm doesn&#39;t currently support infinite or semi-infinite integration domains, where the integration domain is determined by the extrema of the given distributions. So, trying to use a <code>Normal</code> distribution will produce <code>NaN</code></p><pre><code class="language-julia hljs">u0_dist = [Normal(3.0, 2.0)]
gd = GenericDistribution(u0_dist...)
exprob = ExpectationProblem(sm, g, h, gd; nout = length(u0))
sol = solve(exprob, Koopman())
sol.u</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Float64}:
 0.9035426476099572</code></pre><p>Here, the analytical solution is</p><pre><code class="language-julia hljs">exp(p[1] * 4.0) * mean(u0_dist[1])</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.9035826357366064</code></pre><p>Using a truncated distribution will alleviate this problem. However, there is another gotcha. If a large majority of the probability mass of the distribution exists in a small region in the support, then the adaptive methods used to solve the expectation can “miss”  the non-zero portions of the distribution and erroneously return 0.0.</p><pre><code class="language-julia hljs">u0_dist = [truncated(Normal(3.0, 2.0), -1000, 1000)]
gd = GenericDistribution(u0_dist...)
exprob = ExpectationProblem(sm, g, h, gd; nout = length(u0))
sol = solve(exprob, Koopman())
sol.u</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Float64}:
 0.0</code></pre><p>whereas truncating at <span>$\pm 4\sigma$</span> produces the correct result</p><pre><code class="language-julia hljs">u0_dist = [truncated(Normal(3.0, 2.0), -5, 11)]
gd = GenericDistribution(u0_dist...)
exprob = ExpectationProblem(sm, g, h, gd; nout = length(u0))
sol = solve(exprob, Koopman())
sol.u</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Float64}:
 0.9035833577703978</code></pre><p>If a large truncation is required, it is best practice to center the distribution on the truncated interval. This is because many of the underlying quadrature algorithms use the center of the interval as an evaluation point.</p><pre><code class="language-julia hljs">u0_dist = [truncated(Normal(3.0, 2.0), 3 - 1000, 3 + 1000)]
gd = GenericDistribution(u0_dist...)
exprob = ExpectationProblem(sm, g, h, gd; nout = length(u0))
sol = solve(exprob, Koopman())
sol.u</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Float64}:
 0.9035843608115925</code></pre><h2 id="Vector-Valued-Functions"><a class="docs-heading-anchor" href="#Vector-Valued-Functions">Vector-Valued Functions</a><a id="Vector-Valued-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Vector-Valued-Functions" title="Permalink"></a></h2><p><code>ExpectationProblem</code> can also handle vector-valued functions. Simply pass the vector-valued function and set the <code>nout</code> kwarg to the length of the vector the function returns.</p><p>Here, we demonstrate this by computing the expectation of <code>u</code> at <code>t=4.0s</code> and <code>t=6.0s</code></p><pre><code class="language-julia hljs">g(sol, p) = [sol(4.0)[1], sol(6.0)[1]]
exprob = ExpectationProblem(sm, g, h, gd; nout = 2)
sol = solve(exprob, Koopman())
sol.u</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-element Vector{Float64}:
 0.9035843608115925
 0.4958955682159018</code></pre><p>with analytical solution</p><pre><code class="language-julia hljs">exp.(p .* [4.0, 6.0]) * mean(u0_dist[1])</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-element Vector{Float64}:
 0.9035826357366064
 0.4958966646647597</code></pre><p>this can be used to compute the expectation at a range of times simultaneously</p><pre><code class="language-julia hljs">saveat = tspan[1]:0.5:tspan[2]
g(sol, p) = sol[1, :]
prob = ODEProblem(f, u0, tspan, p, saveat = saveat)
sm = SystemMap(prob, Tsit5())
exprob = ExpectationProblem(sm, g, h, gd; nout = length(saveat))
sol = solve(exprob, Koopman())
sol.u</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">21-element Vector{Float64}:
 3.00000342997363
 2.5821268324641955
 2.222456270936201
 1.9128866158620428
 1.6464354737189055
 1.4171010439585803
 1.2197090633820724
 1.0498111825687724
 0.903584360811593
 0.7777191272838139
 ⋮
 0.49589556821590175
 0.42681769377636924
 0.36736961463153206
 0.31620019646595693
 0.27215081053485346
 0.23424232180420576
 0.2016186364835746
 0.17353590778751105
 0.1493637534733821</code></pre><p>We can then plot these values along with the analytical solution</p><pre><code class="language-julia hljs">plot(t -&gt; exp(p[1] * t) * mean(u0_dist[1]), tspan..., xlabel = &quot;t&quot;, label = &quot;analytical&quot;)
scatter!(collect(saveat), sol.u, marker = :o, label = nothing)</code></pre><img src="6294ad67.svg" alt="Example block output"/><h3 id="Benefits-of-Using-Vector-Valued-Functions"><a class="docs-heading-anchor" href="#Benefits-of-Using-Vector-Valued-Functions">Benefits of Using Vector-Valued Functions</a><a id="Benefits-of-Using-Vector-Valued-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Benefits-of-Using-Vector-Valued-Functions" title="Permalink"></a></h3><p>In the above examples, we used vector-valued expectation calculations to compute the various expectations required. Alternatively, one could simply compute multiple scalar-valued expectations. However, in most cases it is more efficient to use the vector-valued form. This is especially true when the ODE to be solved is computationally expensive.</p><p>To demonstrate this, let&#39;s compute the expectation of <span>$x$</span>, <span>$x^2$</span>, and <span>$x^3$</span> using both approaches while counting the number of times <code>g()</code> is evaluated. This is the same as the number of simulation runs required to arrive at the solution. First, consider the scalar-valued approach. Here, we follow the same method as before, but we add a counter to our function evaluation that stores the number of function calls for each expectation calculation to an array.</p><pre><code class="language-julia hljs">function g(sol, p, power, counter)
    counter[power] += 1
    sol(4.0)[1]^power
end
counter = [0, 0, 0]
g(sol, p, power) = g(sol, p, power, counter)
g(sol, p) = g(sol, p, 1)
exprob = ExpectationProblem(sm, g, h, gd; nout = 1)
sol = solve(exprob, Koopman())
sol.u</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.903584360811593</code></pre><pre><code class="language-julia hljs">g(sol, p) = g(sol, p, 2)
exprob = ExpectationProblem(sm, g, h, gd; nout = 1)
sol = solve(exprob, Koopman())
sol.u</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1.1793351995541244</code></pre><pre><code class="language-julia hljs">g(sol, p) = g(sol, p, 3)
exprob = ExpectationProblem(sm, g, h, gd; nout = 1)
sol = solve(exprob, Koopman())
sol.u</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1.7213917763291955</code></pre><pre><code class="language-julia hljs">counter</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3-element Vector{Int64}:
 375
 405
 375</code></pre><p>Leading to a total of <code>j sum(counters)</code> function evaluations.</p><p>Now, let&#39;s compare this to the vector-valued approach</p><pre><code class="language-julia hljs">function g(sol, p, counter)
    counter[1] += 1
    v = sol(4.0)[1]
    [v, v^2, v^3]
end
counter = [0]
g(sol, p) = g(sol, p, counter)
exprob = ExpectationProblem(sm, g, h, gd; nout = 3)
sol = solve(exprob, Koopman())
sol.u</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3-element Vector{Float64}:
 0.9035833264285407
 1.1793351995541244
 1.721398472894846</code></pre><pre><code class="language-julia hljs">counter</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Int64}:
 405</code></pre><p>This is <code>j round(counter[1]/sum(counters)*100,digits=2)</code>% the number of simulations required when using scalar-valued expectations. Note how the number of evaluations used in the vector-valued form is equivalent to the maximum number of evaluations for the 3 scalar-valued expectation calls.</p><h2 id="Higher-Order-Moments"><a class="docs-heading-anchor" href="#Higher-Order-Moments">Higher-Order Moments</a><a id="Higher-Order-Moments-1"></a><a class="docs-heading-anchor-permalink" href="#Higher-Order-Moments" title="Permalink"></a></h2><p>Leveraging this vector-valued capability, we can also efficiently compute higher-order central moments.</p><h3 id="Variance"><a class="docs-heading-anchor" href="#Variance">Variance</a><a id="Variance-1"></a><a class="docs-heading-anchor-permalink" href="#Variance" title="Permalink"></a></h3><p>The variance, or 2nd central moment, of a random variable <span>$X$</span> is defined as</p><p class="math-container">\[\mathrm{Var}\left(X\right)=\mathbb{E}\left[\left(X-\mu\right)^2\right]\]</p><p>where</p><p class="math-container">\[\mu = \mathbb{E}\left[X\right]\]</p><p>The expression for the variance can be expanded to</p><p class="math-container">\[\mathrm{Var}\left(X\right)=\mathbb{E}\left[X^2\right]-\mathbb{E}\left[X\right]^2\]</p><p>Using this, we define a function that returns the expectations of <span>$X$</span> and <span>$X^2$</span> as a vector-valued function and then compute the variance from these</p><pre><code class="language-julia hljs">function g(sol, p)
    x = sol(4.0)[1]
    [x, x^2]
end
exprob = ExpectationProblem(sm, g, h, gd; nout = 2)
sol = solve(exprob, Koopman())
sol.u
mean_g = sol.u[1]
var_g = sol.u[2] - mean_g^2</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.36287237175445763</code></pre><p>For a linear system, we can propagate the variance analytically as</p><p class="math-container">\[e^{2pt}\mathrm{Var}\left(u_0\right)\]</p><pre><code class="language-julia hljs">exp(2 * p[1] * 4.0) * var(u0_dist[1])</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.36287181315765005</code></pre><p>This can be computed at multiple time instances as well</p><pre><code class="language-julia hljs">saveat = tspan[1]:0.5:tspan[2]
g(sol, p) = [sol[1, :]; sol[1, :] .^ 2]
prob = ODEProblem(f, u0, tspan, p, saveat = saveat)
sm = SystemMap(prob, Tsit5())
exprob = ExpectationProblem(sm, g, h, gd; nout = length(saveat) * 2)
sol = solve(exprob, Koopman())
sol.u

μ = sol.u[1:length(saveat)]
σ = sqrt.(sol.u[(length(saveat) + 1):end] - μ .^ 2)

plot(t -&gt; exp(p[1] * t) * mean(u0_dist[1]), tspan...,
     ribbon = t -&gt; -sqrt(exp(2 * p[1] * t) * var(u0_dist[1])),
     label = &quot;Analytical Mean, 1 std bounds&quot;)
scatter!(collect(saveat), μ, marker = :x, yerror = σ, c = :black,
         label = &quot;Koopman Mean, 1 std bounds&quot;)</code></pre><img src="93d2a1d8.svg" alt="Example block output"/><h3 id="Skewness"><a class="docs-heading-anchor" href="#Skewness">Skewness</a><a id="Skewness-1"></a><a class="docs-heading-anchor-permalink" href="#Skewness" title="Permalink"></a></h3><p>A similar approach can be used to compute skewness</p><pre><code class="language-julia hljs">function g(sol, p)
    x = sol(4.0)[1]
    [x, x^2, x^3]
end
exprob = ExpectationProblem(sm, g, h, gd; nout = 3)
sol = solve(exprob, Koopman())
sol.u
mean_g = sol.u[1]
var_g = sol.u[2] - mean_g^2
skew_g = (sol.u[3] - 3.0 * mean_g * var_g - mean_g^3) / var_g^(3 / 2)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3.795455433349072e-9</code></pre><p>As the system is linear, we expect the skewness to be unchanged from the initial distribution. Because the distribution is a truncated Normal distribution centered on the mean, the true skewness is <code>0.0</code>.</p><h2 id="Batch-Mode"><a class="docs-heading-anchor" href="#Batch-Mode">Batch-Mode</a><a id="Batch-Mode-1"></a><a class="docs-heading-anchor-permalink" href="#Batch-Mode" title="Permalink"></a></h2><p>It is also possible to solve the various simulations in parallel by using the <code>batch</code> kwarg and a batch-mode supported quadrature algorithm via the <code>quadalg</code> kwarg. To view the list of batch compatible quadrature algorithms, refer to <a href="https://docs.sciml.ai/Integrals/stable/">Integrals.jl</a>. Note: Batch-mode operation is built on top of DifferentialEquation.jl&#39;s <code>EnsembleProblem</code>. See the <a href="https://docs.sciml.ai/DiffEqDocs/stable/features/ensemble/">EnsembleProblem documentation</a> for additional options.</p><p>The default quadrature algorithm to solve <code>ExpectationProblem</code> does not support batch-mode evaluation. So, we first load dependencies for additional quadrature algorithms</p><pre><code class="language-julia hljs">using IntegralsCuba</code></pre><p>We then solve our expectation as before, using a <code>batch=10</code> multi-thread parallelization via <code>EnsembleThreads()</code> of Cuba&#39;s SUAVE algorithm. We also introduce additional uncertainty in the model parameter.</p><pre><code class="language-julia hljs">u0_dist = truncated(Normal(3.0, 2.0), -5, 11)
p_dist = truncated(Normal(-0.7, 0.1), -1, 0)
gd = GenericDistribution(u0_dist, p_dist)
g(sol, p) = sol(6.0)[1]
h(x, u, p) = [x[1]], [x[2]]
sm = SystemMap(prob, Tsit5(), EnsembleThreads())
exprob = ExpectationProblem(sm, g, h, gd; nout = 1)
# batchmode = EnsembleThreads() #where to pass this?
sol = solve(exprob, Koopman(), batch = 10, quadalg = CubaSUAVE())
sol.u</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Float64}:
 0.053978607864753524</code></pre><p>Now, let&#39;s compare the performance of the batch and non-batch modes</p><pre><code class="language-julia hljs">@time solve(exprob, Koopman(), batch = 10, quadalg = CubaSUAVE())</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">SciMLExpectations.ExpectationSolution{Vector{Float64}, Vector{Float64}, SciMLBase.IntegralSolution{Float64, 1, Vector{Float64}, Vector{Float64}, IntegralProblem{true, RecursiveArrayTools.ArrayPartition{Float64, Tuple{Vector{Float64}, Vector{Float64}}}, SciMLExpectations.var&quot;#28#35&quot;{SciMLExpectations.var&quot;#output_func#34&quot;{GenericDistribution{SciMLExpectations.var&quot;#pdf_func#10&quot;{Tuple{Distributions.Truncated{Distributions.Normal{Float64}, Distributions.Continuous, Float64, Float64, Float64}, Distributions.Truncated{Distributions.Normal{Float64}, Distributions.Continuous, Float64, Float64, Float64}}}, SciMLExpectations.var&quot;#rand_func#12&quot;{Tuple{Distributions.Truncated{Distributions.Normal{Float64}, Distributions.Continuous, Float64, Float64, Float64}, Distributions.Truncated{Distributions.Normal{Float64}, Distributions.Continuous, Float64, Float64, Float64}}}, StaticArraysCore.SVector{2, Float64}, StaticArraysCore.SVector{2, Float64}}, typeof(Main.g)}, SciMLExpectations.var&quot;#27#33&quot;{typeof(Main.h)}, SystemMap{ODEProblem{Vector{Float64}, Tuple{Float64, Float64}, false, Vector{Float64}, ODEFunction{false, SciMLBase.AutoSpecialize, typeof(Main.f), LinearAlgebra.UniformScaling{Bool}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED), Nothing, Nothing}, Base.Pairs{Symbol, StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}, Tuple{Symbol}, @NamedTuple{saveat::StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}}}, SciMLBase.StandardODEProblem}, OrdinaryDiffEq.Tsit5{typeof(OrdinaryDiffEq.trivial_limiter!), typeof(OrdinaryDiffEq.trivial_limiter!), Static.False}, EnsembleThreads, Base.Pairs{Symbol, Union{}, Tuple{}, @NamedTuple{}}}}, StaticArraysCore.SVector{2, Float64}, Base.Pairs{Symbol, Union{}, Tuple{}, @NamedTuple{}}}, IntegralsCuba.CubaSUAVE{Float64}, Vector{Float64}, Nothing}}([0.053978607864753524], [0.004462032598640491], [0.053978607864753524])</code></pre><pre><code class="language-julia hljs">solve(exprob, Koopman(), batch = 0, quadalg = CubaSUAVE())
@time solve(exprob, Koopman(), batch = 0, quadalg = CubaSUAVE())</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">SciMLExpectations.ExpectationSolution{Float64, Vector{Float64}, SciMLBase.IntegralSolution{Float64, 0, Float64, Vector{Float64}, IntegralProblem{false, RecursiveArrayTools.ArrayPartition{Float64, Tuple{Vector{Float64}, Vector{Float64}}}, SciMLExpectations.var&quot;#23#24&quot;{GenericDistribution{SciMLExpectations.var&quot;#pdf_func#10&quot;{Tuple{Distributions.Truncated{Distributions.Normal{Float64}, Distributions.Continuous, Float64, Float64, Float64}, Distributions.Truncated{Distributions.Normal{Float64}, Distributions.Continuous, Float64, Float64, Float64}}}, SciMLExpectations.var&quot;#rand_func#12&quot;{Tuple{Distributions.Truncated{Distributions.Normal{Float64}, Distributions.Continuous, Float64, Float64, Float64}, Distributions.Truncated{Distributions.Normal{Float64}, Distributions.Continuous, Float64, Float64, Float64}}}, StaticArraysCore.SVector{2, Float64}, StaticArraysCore.SVector{2, Float64}}, typeof(Main.h), typeof(Main.g), SystemMap{ODEProblem{Vector{Float64}, Tuple{Float64, Float64}, false, Vector{Float64}, ODEFunction{false, SciMLBase.AutoSpecialize, typeof(Main.f), LinearAlgebra.UniformScaling{Bool}, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED), Nothing, Nothing}, Base.Pairs{Symbol, StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}, Tuple{Symbol}, @NamedTuple{saveat::StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}, Int64}}}, SciMLBase.StandardODEProblem}, OrdinaryDiffEq.Tsit5{typeof(OrdinaryDiffEq.trivial_limiter!), typeof(OrdinaryDiffEq.trivial_limiter!), Static.False}, EnsembleThreads, Base.Pairs{Symbol, Union{}, Tuple{}, @NamedTuple{}}}}, StaticArraysCore.SVector{2, Float64}, Base.Pairs{Symbol, Union{}, Tuple{}, @NamedTuple{}}}, IntegralsCuba.CubaSUAVE{Float64}, Vector{Float64}, Nothing}}(0.053978607864753524, [0.004462032598640491], fill(0.053978607864753524))</code></pre><p>It is also possible to parallelize across the GPU. However, one must be careful of the limitations of ensemble solutions with the GPU. Please refer to <a href="https://github.com/SciML/DiffEqGPU.jl">DiffEqGPU.jl</a> for details.</p><p>Here we load <code>DiffEqGPU</code> and modify our problem to use Float32 and to put the ODE in the required GPU form</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"></div></div><p>Switch <code>EnsembleCPUArray()</code> to <code>EnsembleGPUArray()</code> to make this example work on your GPU. Currently, these docs are built on a machine without a GPU.</p><pre><code class="language-julia hljs">using DiffEqGPU

function f(du, u, p, t)
    @inbounds begin du[1] = p[1] * u[1] end
    nothing
end

u0 = Float32[10.0]
p = Float32[-0.3]
tspan = (0.0f0, 10.0f0)
prob = ODEProblem(f, u0, tspan, p)

g(sol, p) = sol(6.0)[1]

u0_dist = truncated(Normal(3.0f0, 2.0f0), -5.0f0, 11.0f0)
p_dist = truncated(Normal(-0.7f0, 0.1f0), -1.0f0, 0.0f0)
gd = GenericDistribution(u0_dist, p_dist)
g(sol, p) = sol(6.0f0)[1]
h(x, u, p) = [x[1]], [x[2]]
prob = ODEProblem(f, u0, tspan, p)
sm = SystemMap(prob, Tsit5(), EnsembleCPUArray())
exprob = ExpectationProblem(sm, g, h, gd; nout = 1)
sol = solve(exprob, Koopman(), batch = 10, quadalg = CubaSUAVE())
sol.u</code></pre><p>The performance gains realized by leveraging batch GPU processing is problem-dependent. In this case, the number of batch evaluations required to overcome the overhead of using the GPU exceeds the number of simulations required to converge to the quadrature solution.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« Home</a><a class="docs-footer-nextpage" href="../optimization_under_uncertainty/">Optimization Under Uncertainty »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Thursday 25 January 2024 04:33">Thursday 25 January 2024</span>. Using Julia version 1.10.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
